---
description: Mon 1st Sep - Sun 7th Sep 2025
---

# Week 36

## Monday 1st September 2025

### AI Ethics WG

- **Type of meeting:** Weekly
- **Present:** CallyFromAuron [**facilitator**], UKnowZork [**documenter**], CallyFromAuron, UKnowZork, AshleyDawn, Clement Umoh, Alfred Itodele, Sucre n Spice, advanceameyaw, barnabas, Grandi, Jeffrey Ndarake, Maxmilez, Rems
- **Purpose:** Monthly meeting of the AI Ethics Workgroup
- **Working Docs:**
  - [AI Ethics WG budget: Quarter 4 2025](https://docs.google.com/spreadsheets/d/1vLC4ZIHO3WN-Ah9XwehRmbwLZAeePsxxYQXmLiiJLnQ/edit?gid=1840666820#gid=1840666820)
  - [MOOC study group on AI ethics ](https://github.com/SingularityNet-Ambassador-Program/AI-Ethics-Workgroup/issues/142)
  - [AI Ethics WorkGroup Github board](https://github.com/orgs/SingularityNet-Ambassador-Program/projects/1/views/2)

#### Narrative:
Discussion Points:
This is our last meeting of the quarter(Q3)!
The call opened  with updates on payments, noting that several completed tasks are still waiting because of the low AGIX token price. Everyone was reminded that contributors will be paid by the end of the quarter regardless, with the admin team covering the shortfall if needed.
Documentation for this meeting was assigned to Zork, with the reminder that it should be completed and submitted by September 7.
When we reviewed the Github board, a question came up about whether anything should be raised in the upcoming workgroup sync call. Nobody had urgent items, but it was agreed that the BGI Nexus survey should continue to be highlighted.
A discussion followed on possible involvement at BGI25 in Istanbul. Ideas included hosting a virtual event beforehand to showcase the research interviews, transcriptions, and survey data. Vani mentioned that more clarity would come after a check-in with Esther and Hayley later in the week.
On the community engagement side, Vani mentioned that  Colleen’s “Redefining Intelligence” session had technical glitches but was successfully repeated in the AI Sandbox. A recording and slides will be shared and a new participant, Julian, has also suggested topics and may become involved in the future.
Sucre gave an update on internal management: the project board is organized, the Q4 budget draft has been prepared, and the quarterly report is underway. Payments are still delayed by token price, but there’s hope that some will be processed by Thursday.
The MOOC study group on AI ethics was briefly revisited, but the feeling was that workloads are too heavy now. The idea will be reassessed in the October meeting.
We checked the progress on transcripts. Vani noted that Q2 transcript checking is still ongoing but close to completion, while Q3 transcripts are partially done. The backlog remains a priority. 
In connection with BGI25, we talked about how the workgroup might contribute, perhaps through a roundtable or presentation tied to ongoing research. Everyone was invited to suggest subtopics or relevant topics before the Thursday meeting with Esther and Hayley.
The budget review prompted discussion on necessary cuts. Documentation payments were reduced to $20, co-chair to $250, and management roles to $150. Only three new interviews are planned for Q4 (alongside Jeffrey’s completed one), with most of the budget going toward 14 transcriptions. Other allocations included transcript checking, two trial research write-ups, possible grounded theory coding, Colleen’s monthly events, and a contingency fund. AI Ethics WG budget: Quarter 4 2025
Members then exchanged views on who wanted to take on tasks. Zork, Clement, Grandi, and Advance confirmed willingness to do transcriptions. Alfred, MaxMilez, Zork, and Rems offered to handle interviews. We agreed to finalize preferences by commenting directly on the draft budget sheet.
There was clarification around grounded theory coding that was stated in the Q4 budget analysis: it refers to qualitative data analysis, not programming. The idea is to treat it as a learning opportunity, possibly unpaid unless strong interest develops.


#### Decision Items:
- Q4 Budget Focus: We agreed to cut costs across most roles and make transcription the main priority, budgeting for 14 transcriptions (new and backlog) while limiting new interviews to three (plus Jeffrey’s completed one).
  - [**rationale**] We felt it made more sense to slow down on new interviews and put our energy into finishing the backlog transcriptions giving lasting value and make sure the work we’ve already done doesn’t just sit unused. By capping new interviews to just three, plus Jeffrey’s completed one, we can still bring in some fresh perspectives without stretching the budget or creating another pile of unfinished work.
- Completed tasks will be paid by the end of Q3 even if token price remains below target, with the admin team covering any shortfall.
  - [**rationale**] We agreed it wouldn’t be fair to leave people waiting on payments just because the token price is down. Since the work is already done, it should be honored. That’s why the admin team will cover any shortfall — it keeps things fair, shows people their effort is valued, and helps keep motivation strong for future tasks.

#### Action Items:
- [**action**] Vani to meet with Esther & Hayley on Sept 4 to clarify BGI25 Istanbul involvement (virtual event, roundtable, research showcase). [**assignee**] CallyFromAuron [**due**] 4 September 2025 [**status**] todo
- [**action**] Sucre to Finalize and submit Q4 budget by Sept 15; continue preparing quarterly report. [**assignee**] Sucre n Spice [**due**] 15 September 2025 [**status**] in progress
- [**action**] All members are to comment in the draft budget sheet indicating willingness to take on transcriptions or interviews. [**status**] in progress
- [**action**] Vani to complete Q2 transcript checking and progress Q3 transcripts by end of quarter. [**assignee**] CallyFromAuron [**status**] in progress
- [**action**] All members are to revisit interest in the MOOC study group and to consider alternative formats. [**status**] todo
- [**action**] Vani to post more info on grounded theory coding in Discord to gauge member interest. [**assignee**] CallyFromAuron [**due**] 15 September 2025 [**status**] in progress

#### Keywords/tags:
- **topics covered:** AI Ethics MOOC Study group, Interview Transcription, Interviews, budget management, deadlines, grounded theory coding, BGI25 Istanbul, Q4 budget, AGIX rate, Q3 quarterly report, transcript checking.
- **emotions:** collaborative, deliberative, forward-looking
## Thursday 4th September 2025


### Governance Workgroup

- **Type of meeting:** Weekly
- **Present:** Alfred Itodele [**facilitator**], UKnowZork [**documenter**], Alfred Itodele, UKnowZork, guillermolucero, Kateri, CallyFromAuron, Jeffrey Ndarake, LordKizzy, martinsoki, LadyTempestt, AshleyDawn, Maxmilez
- **Purpose:** Regular Weekly GovWG meeting
- **Working Docs:**
  - [Governance Dashboard –  Analytics ](https://docs.google.com/document/d/1qGI7RWjutDtsTfsvpeVgxWK0RahnjwDVnj05upOYZuo/edit?tab=t.0)
  - [Governance calls, rolling agenda](https://docs.google.com/document/d/1t39dwlwLYYB_1z_5szq1rnOH7mVTHe8Tmwv0R6ELOyE/edit?tab=t.0#heading=h.e0i68kevq8jk)

#### Narrative:
We checked the rolling agenda and agreed on discussion topics for sessions that did not yet have a topic assigned. 

Vani brought up a recent Discord discussion about Tevo’s difficulty managing payments outside the quarterly allocation, stressing the need for a clearer system to track and confirm agreements each quarter. She also mentioned Tevo’s new GitHub integration, which could reduce reliance on Dework. 

Guillermo walked us through the governance dashboard tool. He emphasized functionality and mobile usability over styling, showing how proposals would be created by copying reports from Google Docs to keep workflows open and flexible. He demonstrated how budgets and links would be added, how proposals would appear, and how the consent/objection process would work

Improvements suggested:
- "consent" not "voting"
- displaying document titles instead of raw links

We discussed how the dashboard will handle the second round consent process. 

We discussed what analytics should be tracked: see Guillermo's analytics doc. Suggestions included:
- participation patterns
- number of abstentions
- how often particular objections recur for a WG over time (would need input of historic data, and is therefore something for a 2nd iteration rather than something that can be implemented immediately
- demographics (but with a caution that the Dashboard only collects data about country and language, and only if the user chooses to add that to their profile, so data might not be very complete; also, there are many kinds of diversity (sex? sexuality? disability? etc) that we're not collecting any data on, and probably wouldn't due to privacy concerns; so we should be wary of thinking that just "country" and "language" cover all the exclusions and barriers that people face.) 

Alfred asked about dashboard formatting, and Guillermo explained that Google Docs would remain the main space for editing before content is imported into the tool.

We noted that the Dashboard makes the consent process non-anonymous; Guillermo noted that other forms of opinion gathering, such as sentiment surveys like the recent one in July/August, can also be used in future to supplement the consent process, and would almost certainly be anonymous. 

We noted that the development team will be producing "how-to" materials such as walkthru videos, and agreed that GovWG will help to share them.




#### Decision Items:
- We agreed to help share future tutorials and guides that the Dashboard team might create, 
  - [**rationale**] to help contributors use the governance dashboard and lower barriers to participation.

#### Action Items:
- [**action**] Guillermo to make some suggested improvements to the governance dashboard UX (e.g. display document titles instead of raw links, change "vote" to "consent") [**assignee**] guillermolucero [**due**] 8 September 2025 [**status**] in progress
- [**action**] Vani to check and confirm what the agreed quorum is [**assignee**] CallyFromAuron [**due**] 5 September 2025 [**status**] in progress
- [**action**] Vani to review the analytics Tevo used in previous consent rounds, and add any useful ideas from that into Guillermo’s analytics document [**assignee**] CallyFromAuron [**due**] 5 September 2025 [**status**] in progress

#### Keywords/tags:
- **topics covered:** WG reserves, Q4 2025 budget, Governance Dashboard, Consent process, consent vs voting, Anonymity, transparency, Core Contributors , Analytics, KPIs, Engagement
- **emotions:** Collaborative, quiet,  forward-looking, insightful

### AI Sandbox/Think-tank

- **Type of meeting:** Think-Tank
- **Present:** osmium [**facilitator**], Kateri [**documenter**], Gorga Siagian, advanceameyaw, UKnowZork, Jeffrey Ndarake, martinsoki, Alfred Itodele, Santos, LordKizzy
- **Purpose:** Weekly meeting on AI Think Tank discussion on "Should Artificial Intelligence be granted decision-making autonomy in governance and social systems?"
- **Working Docs:**
  - [Agenda Document](https://docs.google.com/document/d/1-4IqzjeIKE0TraGgUWJ8xREDAXh_YX3ySBLqT0Vw1ck/edit?usp=sharing)

#### In this meeting we discussed:
- Ethical implications of granting decision making autonomy to artificial intelligence within governance and social systems:
Vasu introduced concerns regarding ethical dimension, Can AI uphold fairness, transparency and accountability better than humans? Should AI follow strict ethical frameworks or evolve its own? Who is responsible when an AI-governed decision causes harm?
Advanceameyaw argued that fairness, transparency, and accountability are inherently human duties rather than attributes that can be assigned to AI. Vasu supported this view, highlighting the importance of legitimate data and blockchain technology to ensure transparency in AI applications. Kateri noted that AI's judgment is influenced by the data it is fed, which can lead to biased outcomes.

 
- On governance & power: 

should AI have advisory roles only, or actual voting/policy-making powers? Could AI reduce corruption and bias in governance, or amplify hidden biases? Risks of centralized AI control vs. decentralized AI governance.

Lordkizzy argued that accountability for the misuse of AI should fall on the individual user rather than the companies that create AI frameworks. Gorga disagreed, stating that the responsibility lies with the humans and institutions that design and implement AI governance. Vasu added that transparency in AI models is crucial to prevent misuse and suggested that making AI open source could address some concerns.

Vasu discussed the potential role of his “EthosGuard” AI agent in governance, questioning whether such a system should be limited to providing policy recommendations or also empowered to make decisions. Advanceameyaw noted that the topic requires deeper contemplation, while Vasu emphasized the importance of recognizing the implications of AI’s reliance on human-designed algorithms and data.

Lordkizzy questioned the accountability of search engines like Google in relation to the misuse of information, using the example of bomb-making. He emphasized that before the advent of AI, individuals could still access harmful information and that the responsibility lies with the user rather than the provider. He noted that AI makes information more widely accessible, and misuse is a possibility that should be acknowledged.
- Technological Feasibility: 
How advanced must AI systems be before they are entrusted with governance roles?
Can current LLMs or multi-agent systems reason deeply enough for governance-level decision-making?
What safeguards (explainability, audit trails, failsafes) are necessary?

Kateri expressed apprehension about granting AI authority in decision-making, suggesting its role should remain limited, to reduce potential risks. Jeffrey emphasized that the benefits and drawbacks of AI ultimately depend on how it is applied. 

- The meeting concluded before the discussion ended and was adjourned until the next meeting."

#### Keywords/tags:
- **topics covered:** AI impact, EthosGuard, responsibility, AI decision-making, AI autonomy, accountability, AI in governance, AI ethics
- **emotions:** Educative, Interactive, detailed, collaborative, educative